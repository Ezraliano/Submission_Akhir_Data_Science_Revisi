# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17seqf6M-7wd8M6hFzkSNMQ2FnXQWNQyn

# Proyek Akhir: Menyelesaikan Permasalahan Perusahaan Edutech

- Nama: Ezraliano Sachio Krisnadiva
- Email: krisnadiva456@gmail.com
- Id Dicoding: krisna_diva_XZ7R

## Persiapan

### Menyiapkan library yang dibutuhkan
"""



"""
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
import streamlit as st



# 1. Load Dataset
data = pd.read_csv('https://raw.githubusercontent.com/Ezraliano/submission_akhir_data_science_final1/refs/heads/main/data.csv')
data.head()



# Set style untuk visualisasi agar lebih rapi
sns.set(style="whitegrid")
plt.style.use("ggplot")



# Distribusi Variabel Target (Status)
plt.figure(figsize=(6,4))
sns.countplot(x='Status', data=data)
plt.title('Distribusi Status Mahasiswa (Dropout/Tidak)')
plt.xlabel('Status')
plt.ylabel('Jumlah')
plt.show()



#  Distribusi Variabel Numerik
numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns.tolist()

for col in numerical_cols:
    plt.figure(figsize=(10,4))

    # Histogram
    plt.subplot(1,2,1)
    sns.histplot(data[col], kde=True)
    plt.title(f'Distribusi {col}')

    # Boxplot
    plt.subplot(1,2,2)
    sns.boxplot(x=data[col])
    plt.title(f'Boxplot {col}')

    plt.tight_layout()
    plt.show()



categorical_cols = data.select_dtypes(include=['object']).columns.tolist()

for col in categorical_cols:
    plt.figure(figsize=(8,4))
    sns.countplot(y=col, data=data, order=data[col].value_counts().index)
    plt.title(f'Frekuensi {col}')
    plt.xlabel('Jumlah')
    plt.ylabel(col)
    plt.show()



# 4. Data Preprocessing
# Pisahkan fitur dan target
X = data.drop('Status', axis=1)
y = data['Status']



# Identifikasi kolom kategorikal dan numerik
categorical_cols = X.select_dtypes(include=['object']).columns
numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns



# Buat pipeline preprocessing
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_cols),
        ('cat', OneHotEncoder(drop='first'), categorical_cols)
    ])



# Split data menjadi training dan testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)



# 5. Modeling
# Buat pipeline dengan preprocessing, SMOTE, dan Random Forest
model_pipeline = ImbPipeline([
    ('preprocessor', preprocessor),
    ('smote', SMOTE(random_state=42)),
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
])



# Latih model
model_pipeline.fit(X_train, y_train)



# 6. Evaluation
# Prediksi pada data testing
y_pred = model_pipeline.predict(X_test)

# Cetak laporan klasifikasi
print("Classification Report:\n", classification_report(y_test, y_pred))

# Visualisasi confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()



# Feature Importance
# Dapatkan nama fitur setelah preprocessing
feature_names = numerical_cols.tolist()
if len(categorical_cols) > 0:
    feature_names += (model_pipeline.named_steps['preprocessor']
                     .named_transformers_['cat']
                     .get_feature_names_out(categorical_cols).tolist())



# Dapatkan feature importances
importances = model_pipeline.named_steps['classifier'].feature_importances_
feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
print("Feature Importance:\n", feature_importance_df.head(10))



# Visualisasi feature importance
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15))
plt.title('Top 10 Fitur Paling Penting')
plt.show()



# Bagian Streamlit
st.title("Prediksi Status Dropout Mahasiswa")
st.write("Silakan masukkan data mahasiswa di bawah ini:")



# Ambil kolom-kolom input dari data
user_input = {}
for col in X.columns:
    if col in categorical_cols:
        options = data[col].unique().tolist()
        user_input[col] = st.selectbox(f"{col}", options)
    else:
        user_input[col] = st.number_input(f"{col}", float(data[col].min()), float(data[col].max()))



# Jika tombol ditekan
if st.button("Prediksi"):
    # Buat dataframe dari input
    input_df = pd.DataFrame([user_input])

    # Lakukan prediksi
    prediction = model_pipeline.predict(input_df)[0]

    # Tampilkan hasil
    st.success(f"Status Mahasiswa yang Diprediksi: **{prediction}**")

